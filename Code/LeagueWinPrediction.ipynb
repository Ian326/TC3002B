{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Game Output in League Of Legends\n",
    "---\n",
    "**Por: Ian Joab Padron Corona - A01708940**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "===============================================================================\n",
    "Librerias de Python a utilizar en el proyecto\n",
    "===============================================================================\n",
    "pandas: Libreria de manipulacion de datos en DataFrames\n",
    "tensorflow: Libreria de aprendizaje profundo\n",
    "keras: API de alto nivel para crear redes neuronales\n",
    "Sequential: API para crear modelos de redes neuronales\n",
    "Dense: Capa densa (fully connected)\n",
    "Conv2D: Capa de convolucion 2D\n",
    "MaxPooling2D: Capa de max pooling 2D\n",
    "OneHotEncoder: Convertir variables categoricas en numericas creando columnas binarias. ESTE SOLO PARA EL DE TETRIS\n",
    "MinMaxScaler: Normaliza los datos entre 0 y 1\n",
    "train_test_split: Divide los datos en conjuntos de entrenamiento y prueba\n",
    "===============================================================================\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../content/high_diamond_ranked_10min.csv', low_memory=False)\n",
    "data.drop(columns=['gameId'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.boxplot(figsize = (16, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escalamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Escalamiento de las columnas con valores muy grandes\n",
    "columns_to_scale = ['blueTotalGold', 'blueTotalExperience', 'blueGoldDiff', 'blueExperienceDiff', 'blueGoldPerMin',\n",
    "                    'redTotalGold', 'redTotalExperience', 'redGoldDiff', 'redExperienceDiff', 'redGoldPerMin']\n",
    "data_scaled = data.copy()\n",
    "data_scaled[columns_to_scale] = scaler.fit_transform(data[columns_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scaled.boxplot(figsize = (16, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asignar las 'features; X' y la 'target variable; y'\n",
    "X = data_scaled.drop(columns=['blueWins'])\n",
    "y = data_scaled['blueWins']\n",
    "\n",
    "# Dividir los datos en en train y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                                    X,\n",
    "                                                    y,\n",
    "                                                    train_size   = 0.80,\n",
    "                                                    random_state = 42,\n",
    "                                                    shuffle      = True\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_simple(shape):\n",
    "    \"\"\"\n",
    "    This is a simple model multilayer perceptron or neural network.\n",
    "    Your function should return the model.\n",
    "    \"\"\"\n",
    "    model  =  Sequential([\n",
    "                    Dense(128, activation='relu', input_shape=shape),\n",
    "                    Dense(128, activation='relu'),\n",
    "                    Dense(1, activation='sigmoid')\n",
    "            ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model_simple(model):\n",
    "    \"\"\"\n",
    "    This function takes in the model returned from your get_model function, and compiles it with an optimiser,\n",
    "    loss function and metric.\n",
    "    Compile the model using the Adam optimiser (with default settings), the cross-entropy loss function and\n",
    "    accuracy as the only metric.\n",
    "    Your function doesn't need to return anything; the model will be compiled in-place.\n",
    "    \"\"\"\n",
    "    model.compile(optimizer= \"adam\",\n",
    "                  loss = \"binary_crossentropy\",\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_features, train_labels):\n",
    "    \"\"\"\n",
    "    Train the model on the scaled_train_images and train_labels.\n",
    "    Your function should return the training history, as returned by model.fit.\n",
    "    \"\"\"\n",
    "    return model.fit(train_features, train_labels, epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nn = model_simple(X_train.shape[1:])\n",
    "model_nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compile_model_simple(model_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_nn = train_model_simple(model_nn, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.DataFrame(history_nn.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to make the Accuracy vs Epochs plot\n",
    "\n",
    "acc_plot = frame.plot(y=\"accuracy\", title=\"Accuracy vs Epochs\", legend=False)\n",
    "acc_plot.set(xlabel=\"Epochs\", ylabel=\"Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to make the Loss vs Epochs plot\n",
    "\n",
    "acc_plot = frame.plot(y=\"loss\", title = \"Loss vs Epochs\",legend=False)\n",
    "acc_plot.set(xlabel=\"Epochs\", ylabel=\"Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_features, test_labels):\n",
    "    \"\"\"\n",
    "    This function should evaluate the model on the scaled_test_images and test_labels.\n",
    "    Your function should return a tuple (test_loss, test_accuracy).\n",
    "    \"\"\"\n",
    "    test_loss, test_accuracy = model.evaluate(test_features, test_labels)\n",
    "    return (test_loss, test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run your function to evaluate the model Neural Network Dense Layers\n",
    "\n",
    "test_loss, test_accuracy = evaluate_model(model_nn, X_test, y_test)\n",
    "print(f\"Test loss: {test_loss:.4f}\")\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
